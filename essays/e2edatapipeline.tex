\documentclass[a4paper,12pt]{article}

% Author information
\author{Eugen-Cristian RAVARIU, Vladislav TIFTILOV}

% Package imports
\usepackage[utf8]{inputenc}
\usepackage[margin=2cm]{geometry}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{float}
\usepackage{caption}
\usepackage{setspace}
\usepackage{cite} % For bibliography

% Times New Roman font
\usepackage{mathptmx}

% Title and subtitle formatting
\usepackage{titlesec}
\titleformat{\section}{\bfseries\fontsize{14pt}{14pt}\selectfont}{}{}{}
\titleformat{\subsection}{\bfseries\fontsize{12pt}{12pt}\selectfont}{}{}{}

% Line spacing
\setstretch{1.15}

% Figure, table, and algorithm numbering
\renewcommand{\thefigure}{\arabic{figure}}
\renewcommand{\thetable}{\arabic{table}}

% Algorithm package
\usepackage[ruled,vlined]{algorithm2e}

% Document starts
\begin{document}

% Title Section
\begin{titlepage}
    \centering
    {\bfseries\fontsize{14pt}{14pt} DataDot}\par
    \vspace{0.5cm}
    {\bfseries\fontsize{12pt}{12pt} End-to-End Data Pipeline}\par
    \vspace{1cm}
    Eugen-Cristian RAVARIU, Vladislav TIFTILOV\\
    National University of Science and Technology Politehnica Bucharest\\
    \vfill
    \date{\today}
\end{titlepage}

% Abstract Section
\section{Abstract}
\label{sec:abstract}

Fast growing across all the domains of our daily life determined the need for storing and processing 
large amounts of data. The challenges a developer faces is not only caused by the amount of the data,
but also by the variety and quality of the data. Sometimes, the most challenging part is to semantically
understand the data and to extract valuable information from it. This paper presents an end-to-end data
pipeline that aims to automate the process of data transformation and visualization. During the project,
we have discovered the importance of data quality, which made us having to change the dataset several times
in order to get the most meaningful insights. To be able to face real challenges of the big data world, we
chose on purpose an dataset that is both large and complex. The dataset contains information about movies,
including the title, genre, rating, runtime, and the number of votes. We started by cleaning the data and
aggregating the information, then we performed statistical analysis to generate insights. The decision to
use Azure was made because we wanted our solution to be end-to-end, from data ingestion to visualization, on
a single, cloud platform. Another reason was the need for scalability, as the dataset contains over 8GB of data,
and Azure provides the necessary resources to handle large amounts of data. The data pipeline was implemented
using Azure Data Factory, Azure Databricks, Azure Synapse Analytics, and Power BI. The decision to use to
go with a movies dataset was made because we wanted to analyze the trends in the movie industry, but also
because of the complexity of the dataset, which allowed us to get insights based on multiple dimensions, such
as genre, rating, runtime, and region.

% Main Content
\section{Introduction}
\label{sec:introduction}

Movies are a popular form of entertainment and are watched by millions of people around the world. The dataset contains information about movies, including the title, genre, rating, runtime, and the number of votes. The goal of this project is to analyze the dataset and provide insights into the distribution of movies based on the genre, rating, runtime, and region. The analysis will help us understand the trends in the movie industry and identify the most popular genres, regions, and runtime. The insights will be visualized using Power BI to create a dashboard that can be used to explore the data and gain a deeper understanding of the movie industry.

The main challenges of the project is caused by the size of the dataset and the need to automate the data transformation process. The dataset contains over 8GB of data and is stored in multiple CSV files. The data transformation process involves cleaning the data, aggregating the information, and performing statistical analysis to generate insights. The data pipeline will be implemented using Azure Data Factory, Azure Databricks, Azure Synapse Analytics, and Power BI to automate the data transformation process and create a dashboard for visualization.

\section{Implementation}
\label{sec:implementation}

Describe the methods, equations, and algorithms used.

\section{Conclusions}
\label{sec:conclusions}

Present and discuss the results. Include figures and tables as needed.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{example-image}
    \caption{Example figure caption.}
    \label{fig:example}
\end{figure}

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        Column 1 & Column 2 & Column 3 \\
        \hline
        Data 1 & Data 2 & Data 3 \\
        \hline
    \end{tabular}
    \caption{Example table caption.}
    \label{tab:example}
\end{table}

\section{Conclusion}
\label{sec:conclusion}

TBA

% Example citation
\cite{article}
% References Section
\bibliographystyle{ieeetr} % You can change to "apa" or others if required
\bibliography{references} % Create a references.bib file for bibliography entries

\end{document}
